{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849dec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformer import Transformer\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "from nlp_metrics.eval import EvalCap\n",
    "import fastwer\n",
    "\n",
    "from Dataset import Dataset,PadCollate\n",
    "from helpers import text_to_labels, labels_to_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3853781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "root = '/vol/bitbucket/bh1511/GRID_AV/data'\n",
    "tokenizer = Tokenizer.from_file(\"/vol/bitbucket/bh1511/data/dataset/grid.json\")\n",
    "vf_root = '/vol/bitbucket/bh1511/data'\n",
    "speaker_list = os.listdir(root)\n",
    "test = [\"s1\",\"s2\",\"s20\",\"s22\"]\n",
    "validation = [\"s3\",\"s4\",\"s23\",\"s24\"]\n",
    "training = list(set(speaker_list) - set(test) - set(validation))\n",
    "device = torch.device('cuda')\n",
    "image_or_mesh = \"image\"\n",
    "level = \"word\"\n",
    "pos_input = 80\n",
    "\n",
    "if level == \"word\":\n",
    "    pos_target = 7\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "else:\n",
    "    pos_target = 34\n",
    "    vocab_size = 34\n",
    "\n",
    "\n",
    "# post processor \n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
    "        (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# initial dataset\n",
    "dataset = Dataset(root,vf_root, level, image_or_mesh)\n",
    "\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "\n",
    "val_indices = list(range(2*1000,4*1000)) + list(range(21*1000, 23*1000))\n",
    "test_indices = list(range(2*1000)) + list(range(19*1000, 21*1000))\n",
    "train_indices = list(set(indices) - set(val_indices) - set(test_indices))\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler  = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           sampler=train_sampler, \n",
    "                                           collate_fn=PadCollate(True,tokenizer,level, 0),\n",
    "                                           num_workers = 8,\n",
    "                                           pin_memory=True,\n",
    "                                           persistent_workers=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                                batch_size=batch_size,\n",
    "                                                sampler=valid_sampler,\n",
    "                                                collate_fn=PadCollate(False,tokenizer, level, 0),\n",
    "                                                num_workers = 8,\n",
    "                                                pin_memory=True,\n",
    "                                                persistent_workers=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          sampler=test_sampler,\n",
    "                                          collate_fn=PadCollate(False,tokenizer, level, 0),\n",
    "                                          num_workers = 8,\n",
    "                                          pin_memory=True,\n",
    "                                          persistent_workers=True)\n",
    "\n",
    "\n",
    "num_layers = 8\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "\n",
    "if image_or_mesh == \"image\":\n",
    "    vid_feat_size=512\n",
    "else:\n",
    "    vid_feat_size=468*3\n",
    "    \n",
    "    \n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    video_feature_size=vid_feat_size,\n",
    "    target_vocab_size=vocab_size,\n",
    "    pos_input=pos_input,\n",
    "    pos_target=pos_target,\n",
    "    rate=dropout_rate,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e267c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# label smoothing\n",
    "class LabelSmoothLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        super(LabelSmoothLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def loss(self, input, target):\n",
    "        log_prob = F.log_softmax(input, dim=-1)\n",
    "        weight = input.new_ones(input.size()) * \\\n",
    "            self.smoothing / (input.size(-1) - 1.)\n",
    "        weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\n",
    "        loss = (-weight * log_prob).sum(dim=-1)\n",
    "        return loss\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        # change to 30\n",
    "        if level == \"word\":\n",
    "            mask = torch.logical_not(torch.eq(target, 3))\n",
    "        else:\n",
    "            mask = torch.logical_not(torch.eq(target, 30))\n",
    "        loss_ = self.loss(input, target)\n",
    "        mask = mask.type(dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        return torch.sum(loss_)/torch.sum(mask)\n",
    "    \n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # change to 30\n",
    "    if level == \"word\":\n",
    "        mask = torch.logical_not(torch.eq(real, 3))\n",
    "    else:\n",
    "        mask = torch.logical_not(torch.eq(real, 30))\n",
    "    loss_ = loss_object(pred.permute([0, 2, 1]), real)\n",
    "    mask = mask.type(dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return torch.sum(loss_)/torch.sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred, training):\n",
    "    if level == \"word\":\n",
    "        mask = torch.logical_not(torch.eq(real, 3))\n",
    "    else:\n",
    "        mask = torch.logical_not(torch.eq(real, 30))  \n",
    "        \n",
    "    if training == True:\n",
    "        accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
    "    else:\n",
    "        accuracies = torch.eq(real, pred)\n",
    "\n",
    "    accuracies = torch.logical_and(mask, accuracies)\n",
    "    accuracies = accuracies.type(dtype=torch.float32)\n",
    "    mask = mask.type(dtype=torch.float32)\n",
    "    acc = torch.sum(accuracies)/torch.sum(mask)\n",
    "    return acc\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.00001, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "class CustomSchedule(object):\n",
    "    def __init__(self, _d_model, warmup_steps=1000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = _d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def adjust_learning_rate(self, optim, step):\n",
    "        arg1 = np.reciprocal(np.sqrt(step+3000))\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        lr = np.reciprocal(np.sqrt(self.d_model)) * np.minimum(arg1, arg2)\n",
    "        for param_group in optim.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr\n",
    "\n",
    "# scheduler = CustomSchedule(d_model, warmup_steps=1000)\n",
    "label_sm =  LabelSmoothLoss(0.3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1,2,3,4], gamma=0.1)\n",
    "data_loaders = {\"train\": train_loader, \"val\": validation_loader}\n",
    "data_lengths = {\"train\": len(train_loader), \"val\": len(validation_loader)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565d4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, enc_mask, level):\n",
    "    if level == \"word\":   \n",
    "        # The first token to the transformer should be the start token\n",
    "        max_length = 6\n",
    "        target = torch.from_numpy(np.array([[1]],dtype = np.int32)).to(device=device, non_blocking=True)\n",
    "    else:\n",
    "        max_length = 32\n",
    "        target = torch.from_numpy(np.array([[31.]],dtype = np.int32)).to(device=device, non_blocking=True)\n",
    "\n",
    "    for i in range(max_length):\n",
    "\n",
    "        if level == \"word\":   \n",
    "            # The first token to the transformer should be the start token\n",
    "            dec_target_padding_mask = torch.eq(target, 3).type(torch.float32)\n",
    "        else:\n",
    "            dec_target_padding_mask = torch.eq(target, 30).type(torch.float32)\n",
    "\n",
    "        look_ahead_mask = (1 - torch.ones((target.size(1), target.size(1))).tril()).to(device=device, non_blocking=True)\n",
    "        combined_mask = torch.maximum(dec_target_padding_mask[:, None, None, :], look_ahead_mask).to(device=device, non_blocking=True)\n",
    "\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(output,\n",
    "                                                     target,\n",
    "                                                     False,\n",
    "                                                     enc_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     None)\n",
    "\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = torch.argmax(predictions, dim=-1)\n",
    "        \n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "#         if level == \"word\":\n",
    "#             if predicted_id == 2:\n",
    "#                 break\n",
    "#         else:\n",
    "#             if predicted_id == 32:\n",
    "#                 break\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        target = torch.cat([target, predicted_id], dim=-1)\n",
    "\n",
    "    return torch.squeeze(target, dim=0)[1:], attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd608dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">> Phase: train >> Global Step 392: loss=3.0285, acc=0.2821 lr=0.0000100: 100%|██████████| 391/391 [05:08<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train >> Epoch 1: avg_step_loss=3.14441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Phase: val acc=0.2188 : 100%|██████████| 63/63 [07:13<00:00,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = 1\n",
    "\n",
    "# loop over the dataset multiple times\n",
    "for epoch in range(1):  \n",
    "    \n",
    "    # report the location of the mistake\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    # for phase in ['val', 'train']:\n",
    "    for phase in ['train', 'val']:\n",
    "        loader = data_loaders[phase]\n",
    "        length = data_lengths[phase]\n",
    "        \n",
    "        t = tqdm(enumerate(loader), total=length)\n",
    "        total_loss = 0\n",
    "        \n",
    "        if phase == 'train':\n",
    "            for (i, (inp, tar, enc_mask, combined_mask)) in t:\n",
    "\n",
    "                output = inp.to(device=device, non_blocking=True)\n",
    "                tar = tar.to(device=device, non_blocking=True)\n",
    "                enc_mask = enc_mask.to(device=device, non_blocking=True)\n",
    "                combined_mask = combined_mask.to(device=device, non_blocking=True)\n",
    "                tar_inp = tar[:, :-1]\n",
    "                tar_real = tar[:, 1:]\n",
    "                \n",
    "\n",
    "                \n",
    "                # Clear gradients w.r.t. parameters\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # adjust learning rate for training step\n",
    "                # current_lr = scheduler.adjust_learning_rate(optimizer, global_step)\n",
    "                # Forward pass to get output/logits\n",
    "                predictions, attention_weights = transformer(output, tar_inp,\n",
    "                                             True,\n",
    "                                             enc_mask,\n",
    "                                             combined_mask,\n",
    "                                             None)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Calculate Sparse Categorical Loss\n",
    "                # loss = loss_function(tar_real, predictions)\n",
    "                loss = label_sm(predictions, tar_real)\n",
    "                acc = accuracy_function(tar_real, predictions, True)\n",
    "                \n",
    "\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # Updating parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                global_step += 1\n",
    "\n",
    "                # Updating step parameters\n",
    "                total_loss += loss.detach().item()\n",
    "\n",
    "                lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "\n",
    "                t.set_description(f'>> Phase: {phase} '\n",
    "                                  f'>> Global Step {global_step}: '\n",
    "                                  f'loss={loss.detach().item():.4f}, '\n",
    "                                  f'acc={acc:.4f} '\n",
    "                                  f'lr={lr:.7f}')\n",
    "\n",
    "            print(f'Phase: {phase} >> Epoch {epoch+1}: avg_step_loss={total_loss / length:.5f}')\n",
    "            \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                for (i, (inp, tar, enc_mask)) in t:\n",
    "\n",
    "                    tar = tar.to(device=device, non_blocking=True)\n",
    "                    output = inp.to(device=device, non_blocking=True)\n",
    "                    enc_mask = enc_mask.to(device=device, non_blocking=True)\n",
    "                    sentences = []\n",
    "                    for v in range(output.size(0)):\n",
    "                        sentence, _ = evaluate(output[v].unsqueeze(0), enc_mask[v].unsqueeze(0), level)\n",
    "                        sentences.append(sentence)\n",
    "\n",
    "                    predictions = torch.stack(sentences, dim=0)\n",
    "                    \n",
    "                    real = tar[:, 1:-1]\n",
    "                    acc = accuracy_function(real, predictions, False)\n",
    "                    t.set_description(f'>> Phase: {phase} '\n",
    "                      f'acc={acc:.4f} ')\n",
    "                    \n",
    "                    model_name = \"transformer\" + \"_\" +phase \n",
    "                    torch.save(transformer, model_name+'.pt')\n",
    "    scheduler.step()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e4c388",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc=0.1667: 100%|██████████| 63/63 [04:42<00:00,  3.79s/it]\n"
     ]
    }
   ],
   "source": [
    "#### test\n",
    "\n",
    "transformer_test = torch.load('transformer_val.pt',map_location=torch.device('cuda'))\n",
    "t = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "real_list = []\n",
    "pre_list = []\n",
    "with torch.no_grad():\n",
    "    for (i, (inp, tar, enc_mask)) in t:\n",
    "        tar = tar.to(device=device, non_blocking=True)\n",
    "        output = inp.to(device=device, non_blocking=True)\n",
    "        enc_mask = enc_mask.to(device=device, non_blocking=True)\n",
    "        sentences = []\n",
    "        for v in range(output.size(0)):\n",
    "            sentence, _ = evaluate(output[v].unsqueeze(0), enc_mask[v].unsqueeze(0), level)\n",
    "            sentences.append(sentence)\n",
    "\n",
    "        predictions = torch.stack(sentences, dim=0)\n",
    "        real = tar[:, 1:-1]\n",
    "\n",
    "        acc = accuracy_function(real, predictions, False)\n",
    "\n",
    "        real_list.append(real)\n",
    "        pre_list.append(predictions)\n",
    "        t.set_description(f'acc={acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fda535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### metrics\n",
    "\n",
    "# decode token ids to sentence\n",
    "ground_truth = []\n",
    "hypothesis = []\n",
    "\n",
    "for i in range(len(real)):\n",
    "    for j in range(real[i].size()[0]):\n",
    "        if level == \"word\":\n",
    "            ground_truth.append(tokenizer.decode(real_list[i][j].tolist()))\n",
    "            hypothesis.append(tokenizer.decode(pre_list[i][j].tolist()))\n",
    "        else:\n",
    "            index = torch.sum(real_list[i][j]  != 30)-1\n",
    "            ground_truth.append(labels_to_text(real_list[i][j][:index]))\n",
    "            hypothesis.append(labels_to_text(pre_list[i][j][:index]))\n",
    "# calculate wer and cer\n",
    "# wer\n",
    "print(fastwer.score(hypothesis, ground_truth))\n",
    "# cer\n",
    "print(fastwer.score(hypothesis, ground_truth, char_level=True))\n",
    "# get metric\n",
    "my_metric = EvalCap(ground_truth,hypothesis)\n",
    "my_metric.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aecd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2a91d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
